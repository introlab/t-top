<launch>
    <node pkg="cv_camera" type="cv_camera_node" name="cv_camera_node">
        <param name="rate" value="15"/>
        <param name="device_id" value="0"/>
        <param name="image_width" value="1280"/>
        <param name="image_height" value="720"/>

        <remap from="cv_camera_node/image_raw" to="image_raw"/>
    </node>

    <node pkg="video_analyzer" type="video_analyzer_2d_node.py" name="video_analyzer_node">
        <param name="use_descriptor_yolo" value="false"/>
        <param name="yolo_model" value="yolo_v7_tiny_coco"/>
        <param name="confidence_threshold" value="0.50"/>
        <param name="nms_threshold" value="0.5"/>
        <param name="person_probability_threshold" value="0.5"/>
        <param name="pose_confidence_threshold" value="0.4"/>
        <param name="inference_type" value="torch_gpu"/>

        <param name="pose_enabled" value="true"/>
        <param name="face_descriptor_enabled" value="false"/>
        <param name="semantic_segmentation_enabled" value="false"/>
        <param name="semantic_segmentation_dataset" value="coco"/> <!-- coco, kitchen_open_images or person_other_open_images -->
        <param name="cropped_image_enabled" value="false"/>

        <remap from="analysed_image/filter_state" to="video_analyzer/analysed_image/filter_state"/>
        <remap from="image_raw/filter_state" to="video_analyzer/image_raw/filter_state"/>
    </node>

    <node pkg="pose_classifier" type="pose_classifier_node.py" name="pose_classifier_node" output="screen">
        <param name="pose_confidence_threshold" value="0.4"/>
    </node>

</launch>
