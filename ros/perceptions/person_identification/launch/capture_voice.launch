<launch>
    <arg name="name"/>
    <arg name="neural_network_inference_type"/> <!-- Options: cpu, torch_gpu or trt_gpu -->

    <arg name="output" default="log"/>

    <node pkg="odas_ros" type="odas_server_node.py" name="odas_server_node">
        <param name="configuration_path" value="$(find t_top)/config/configuration_16SoundsUSB.cfg"/>
        <param name="frame_id" value="odas"/>

        <remap from="sss" to="audio_signed_16_44100"/>
        <remap from="sst" to="audio_sst"/>
    </node>

    <node pkg="audio_utils" type="resampling_node.py" name="resampling_node">
        <param name="input_format" value="signed_16"/>
        <param name="output_format" value="signed_16"/>
        <param name="channel_count" value="1"/>
        <param name="input_sampling_frequency" value="44100"/>
        <param name="output_sampling_frequency" value="16000"/>
        <param name="input_frame_sample_count" value="2048"/>

        <remap from="audio_in" to="audio_signed_16_44100"/>
        <remap from="audio_out" to="audio_signed_16_16000"/>
    </node>

    <node pkg="audio_analyzer" type="audio_analyzer_node.py" name="audio_analyzer_node">
        <param name="multiclass_audio_descriptor" value="true"/>
        <param name="inference_type" value="$(arg neural_network_inference_type)"/>
        <param name="interval" value="32000"/> <!-- Low quality audio-->
        <param name="voice_probability_threshold" value="0.5"/>
        <param name="class_probability_threshold" value="0.5"/>

        <remap from="low_quality_audio_in" to="audio_signed_16_16000"/>
        <remap from="high_quality_audio_in" to="audio_signed_16_44100"/>
        <remap from="audio_in/filter_state" to="audio_analyzer/filter_state"/>
        <remap from="sst" to="audio_sst"/>
    </node>

    <node pkg="person_identification" type="capture_voice_node.py" name="capture_voice_node" output="$(arg output)">
        <param name="name" value="$(arg name)"/>
        <param name="mean_size" value="10"/>
    </node>
</launch>
